{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display:flex; border-bottom:4px solid gray; background-color: white; padding: 10px;\">\n",
    "    <div>\n",
    "        <h2 style=\"margin:10px 0px 0px 0px;\">Master Thesis - Spring 2023</h2>\n",
    "        <h4 style=\"margin:10px 10px 10px 0px;\"><i>Artificial Intelligence - Data Science</i></h4>\n",
    "    </div>\n",
    "    <img src=\"https://raw.githubusercontent.com/JABE22/Image/main/Logos/logo_ural-federal-university.png\" style=\"width:300px; height:150px; margin-right: 25px;\" align='right' />\n",
    "</div>\n",
    "<h4 style=\"margin-top:10px; text-align:right; font-size: 20px; margin-right: 25px;\"> Jarno Matarmaa - 03.2023 - Version draft</h4>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sport Activity Classification using Standard CML Models and Time Series Analysis\n",
    "### Part (2/3), Time Series Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASKS**\n",
    "- [25.1.2023] Check if there is possibility to get optimal intervals from single sequences using some threshold values for speed etc.\n",
    "\n",
    "**CHANGE LOG**\n",
    "\n",
    "**QUESTIONS**\n",
    "- [25.2.2023] How to include signal length analysis? Without massive workload, many runs of time consuming algortihms etc.."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a> <br>\n",
    "## I - Table of Contents\n",
    "\n",
    "#### [1 - Data import and preview](#1)\n",
    "* [1A - Libraries](#11)\n",
    "* [1B - Data download](#11)\n",
    "\n",
    "#### [2 - Dataset](#2)\n",
    "* [2A - Data setup](#21)\n",
    "* [2B - Train-Test data splitting *(stratified by y)*](#22)\n",
    "* [2C - Data Standardization *(for visualization)*](#23)\n",
    "\n",
    "#### [3 - Univariate Time Series Classification (UTSC)](#3)\n",
    "* [3A - Libraries and functions](#31)\n",
    "* [3B - Data setup](#32)\n",
    "* [3C - Univariate TSC model classification](#33)\n",
    "\n",
    "#### [4 - Multivariate Time Series Classification (MTSC)](#4)\n",
    "* [4A - Libraries and functions](#41)\n",
    "* [4B - Data setup](#42)\n",
    "* [4C - Multivariate TSC model classification](#43)\n",
    "* [4D - Ensemble classification](#44)\n",
    "\n",
    "#### [5 - Test Section](#5)\n",
    "* [5A - Pipeline](#51)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "## [▲](#0) 1 - Data import and preview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"11\"></a> <br>\n",
    "### [▲](#1) 1A - Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System tools\n",
    "import os\n",
    "import sys\n",
    "# File structure\n",
    "from directory_structure import Tree\n",
    "# Data manipulation tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "# Datetime\n",
    "import datetime\n",
    "# Data visualization tools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "# Seaborn setup\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('./styles/plotstyles.mplstyle')\n",
    "cmap = sns.color_palette(\"muted\", 10)\n",
    "THEMA_COLOR = cmap[9]\n",
    "#plt.style.use('default')\n",
    "#sns.set_style('white', { 'axes.spines.right': False, 'axes.spines.top': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_start = datetime.datetime.now()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"12\"></a> <br>\n",
    "### [▲](#1) 1B - Data download"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File path setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"C:/Users/jarno/OneDrive - УрФУ/STUDIES/MASTER/DATA/\"\n",
    "DATA_PATH_ORG = \"C:/Users/jarno/OneDrive - УрФУ/STUDIES/DesignWorkshop/DesignWorkshopProject/DATA/CSVDATA/SET1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filepath = DATA_PATH + 'results/'\n",
    "preds_filepath = DATA_PATH + 'predictions/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Tree(DATA_PATH, absolute=False)\n",
    "print(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use pickle api to handle numpy format data (.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_SEGMENTED = cPickle.load( open( \"DATA/data_arrays/seq_segmented.pkl\", \"rb\" ) )\n",
    "INDEX_DATA = pd.read_csv(\"DATA/data_arrays/index_data.csv\")\n",
    "SEQ_SEGMENTED_LABELS = pd.read_csv(\"DATA/data_arrays/seq_segmented_labels.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "## [▲](#0) 2 - Data setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"21\"></a> <br>\n",
    "### [▲](#2) 2A - Train-Test data splitting *(stratified by y)*\n",
    "\n",
    "- Dataset generation from the sequencies\n",
    "- Train and Test splits\n",
    "- Functions for data variable initialization\n",
    "- Global variable `SEQ_LEN` will be initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sktime.datatypes._panel._convert import from_2d_array_to_nested\n",
    "from sktime.transformations.panel.reduce import Tabularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These variables need to defined here to avoid (not defined warning in the Data setup functions)\n",
    "DATA, LABELS = (None, None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data setup functions**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This is a function to create interlaced univariate signals from 3-dimensional data given as parameter (sequences)\n",
    "\n",
    "Function can split sequences to a smaller parts (seq_start - seq_end) parameters\n",
    "    - If sequences has already desired size, use seq_start=0 and seq_end=sequences.shape[1] * sequences.shape[2], \n",
    "      for example, if sequences.shape = (1160, 69, 3) => 69 * 3 = 207\n",
    "    - Default values are set to [0, 100]\n",
    "\n",
    "Thus, this function generates equal length segments as an output with a certain precondition:\n",
    "    - Interval length [seq_start,seq_end] must be equal or greater than the length of shortest sequence multiplied by sequences.shape[2]\n",
    "    - For example, if sequences.shape = (1160, [20-69], 3), interval length [seq_start,seq_end] must be 20 * 3 = 60 at the maximum.\n",
    "\n",
    "Example:\n",
    "\n",
    "SEGS.shape = (1160, 69, 3)\n",
    "LBLS.shape = (1160,)\n",
    "\n",
    "Proper function call example to use all the input data:\n",
    "\n",
    "x_data, y_data = create_dataset(SEGS, LBLS, 0, 207, True, True)\n",
    "\n",
    "x_data.shape = (1160, 207)  (has equal length segments 207)\n",
    "y_data.shape = (1160,)\n",
    "\n",
    "If you want to cut signals after interlation, you can select the desired interval using seq_start and seq_end as you wish\n",
    "\n",
    "'''\n",
    "\n",
    "def create_dataset(sequences, targets, seq_start=0, seq_end=100, std=False, info=True):\n",
    "\n",
    "    if info: print(\"\\nSequence/Targets length validity check: \", len(sequences), len(targets))\n",
    "\n",
    "    target = targets.label.astype('category').cat.codes\n",
    "\n",
    "    seq_len = seq_end - seq_start\n",
    "\n",
    "    x_data = np.zeros((len(sequences), seq_len))\n",
    "    y_data = np.zeros(len(sequences))\n",
    "\n",
    "    if info: print(x_data.shape, y_data.shape)\n",
    "\n",
    "    for i, s in zip(range(0,len(sequences)), sequences):\n",
    "        # s = 69x3 shape single 3-dimensional segment/sequence \n",
    "        if info: print(i,s.shape)\n",
    "        # Sequence manipulation\n",
    "        signal = s.reshape(-1,1)                 # Generates interlation operation: (69,3) => (207,1) \n",
    "        signal = np.squeeze(np.asarray(signal))  # Remove axes of length one:       (207,1) => (207,)\n",
    "        signal = signal[seq_start:seq_end]       # Selects sub segments, e.g. signal[0:100] => (100,)\n",
    "        #if info: print(signal.shape)\n",
    "        x_data[i] = signal\n",
    "        y_data[i] = target[i]\n",
    "\n",
    "    if std:\n",
    "        if info: print(\"Standardization\")\n",
    "        x_data = StandardScaler().fit_transform(x_data)\n",
    "\n",
    "    print('X:', x_data.shape, ' y:', y_data.shape)\n",
    "\n",
    "    return x_data, y_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested data variable reset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if data variable reset needed\n",
    "def initdata_xynested(seq_start, seq_end):\n",
    "    global x_data, y_data\n",
    "    global x_train, x_test, y_train, y_test\n",
    "    global X_train_nest, X_test_nest\n",
    "    # The whole data\n",
    "    x_data, y_data = create_dataset(DATA, LABELS, seq_start=seq_start, seq_end=seq_end, std=False, info=False)\n",
    "    # Train-Test data splits\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=24, stratify=y_data, shuffle=True)\n",
    "    print('Train:', x_train.shape, y_train.shape, 'Test:', x_test.shape, y_test.shape)\n",
    "    # Multivariate\n",
    "    X_train_nest = from_2d_array_to_nested(x_train)\n",
    "    X_test_nest  = from_2d_array_to_nested(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested data variable reset function (Standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if standard data variable reset needed\n",
    "def initdata_xynested_std(seq_start, seq_end):\n",
    "    global x_data_std, y_data\n",
    "    global x_train_std, x_test_std, y_train, y_test\n",
    "    global X_train_nest_std, X_test_nest_std\n",
    "    # The whole data (standard)\n",
    "    x_data_std, y_data = create_dataset(DATA, LABELS, seq_start=seq_start, seq_end=seq_end, std=True, info=False)\n",
    "    # Train-Test data splits (standard)\n",
    "    x_train_std, x_test_std, y_train, y_test = train_test_split(x_data_std, y_data, test_size=0.2, random_state=24, stratify=y_data, shuffle=True)\n",
    "    print('Train:', x_train_std.shape, y_train.shape, 'Test:', x_test_std.shape, y_test.shape)\n",
    "    # Multivariate\n",
    "    X_train_nest_std = from_2d_array_to_nested(x_train_std)\n",
    "    X_test_nest_std  = from_2d_array_to_nested(x_test_std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabular data reset function\n",
    "\n",
    "- This function uses global variables `X_train_nest_std`, `X_test_nest_std` and tabularizes them. Therefore recommended to use only together with nested data variable reset functions\n",
    "- New global variables `X_train_tab`, `X_test_tab`, `X_train_tab_std` and `X_test_tab_std` will be initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initdata_xytabular(std=False):\n",
    "    global X_train_tab, X_test_tab\n",
    "    tabu = Tabularizer()\n",
    "    X_train_tab = tabu.fit_transform(X_train_nest)\n",
    "    X_test_tab = tabu.fit_transform(X_test_nest)\n",
    "\n",
    "    if std:\n",
    "        global X_train_tab_std, X_test_tab_std\n",
    "        tabu = Tabularizer()\n",
    "        X_train_tab_std = tabu.fit_transform(X_train_nest_std)\n",
    "        X_test_tab_std = tabu.fit_transform(X_test_nest_std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data reset function\n",
    "\n",
    "`init_data(seq_start, seq_end, nest=True, tab=False, std=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_data(seq_start, seq_end, nest=True, tab=False, std=False):\n",
    "    # Initilaizes nested data variables for sktime classification models\n",
    "    if nest:\n",
    "        initdata_xynested(seq_start, seq_end)\n",
    "        # Standard\n",
    "        if std:\n",
    "            initdata_xynested_std(seq_start, seq_end)\n",
    "\n",
    "    # Initializes tabular data for sklearn classifiers\n",
    "    if tab:\n",
    "        initdata_xytabular()\n",
    "        # Standard\n",
    "        if std:\n",
    "            initdata_xytabular(std=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize data**\n",
    "- Initializes global data variables according to the given parameters\n",
    "- Creates the data splits (and feedback prints according to the *create_dataset()* function)\n",
    "\n",
    "***Important note!***\n",
    "\n",
    "In variable `SEQ_SEGMENTED` data is already in equal length segments from the interval of `[0,1000]` (5x200). So, when creating segments it is defined that we get 5 splits in the length of 200 from the original sequence. It implies that `init_data()` function call can therefore use the range of `[0,600] (3x200=600)` because `create_dataset()` function flattens the three dimensional data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select data**\n",
    "\n",
    "Note: Only selected data is processed. Selection is global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for full length sequences\n",
    "#DATA, LABELS = (SEQ_FILTERED, INDEX_DATA)\n",
    "#SEQ_START = 100\n",
    "#SEQ_END = int(seq_analysis_df['Filtered']['min'])\n",
    "\n",
    "# Setup for segmented equal length sequences\n",
    "DATA, LABELS = (SEQ_SEGMENTED, SEQ_SEGMENTED_LABELS)\n",
    "SEQ_START = 0\n",
    "SEQ_END = 69*3 # E.g., if SEG_LEN=69, we use 3*69=207 \"multivariate\" signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_START, SEQ_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_data(SEQ_START, SEQ_END, nest=True, tab=True, std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nest_std.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random time series plots (for analysis)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before visualization we need to get sports from the codes 0-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPORT_CODES = {0: \"Biking\", 1:\"Running\", 2: \"Other\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1,figsize=(10,6))\n",
    "sns.lineplot(x_train[16], ax=ax[0])\n",
    "ax[0].set_xlabel('Signal length (s)')\n",
    "ax[0].set_ylabel('Value (std)')\n",
    "ax[0].set_title(\"Activity type = %s\" % SPORT_CODES[y_train[16]])\n",
    "ax[0].grid()\n",
    "\n",
    "sns.lineplot(x_test[7], ax=ax[1])\n",
    "ax[1].set_xlabel('Signal length (s)')\n",
    "ax[1].set_ylabel('Value (std)')\n",
    "ax[1].set_title(\"Activity type = %s\" % SPORT_CODES[y_test[7]])\n",
    "ax[1].grid()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"22\"></a> <br>\n",
    "### [▲](#2) 2B - Data Standardization *(for visualization)*\n",
    "\n",
    "- Data can be standardized using **create_dataset(** *std=True* **)** function parameter\n",
    "- This section procedure has precondition that **x_train** and **x_test** data is in two dimensional space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train_std = scaler.fit_transform(x_train)\n",
    "x_test_std = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1,figsize=(10,6))\n",
    "sns.lineplot(x_train_std[16], ax=ax[0])\n",
    "ax[0].set_xlabel('Signal length (s)')\n",
    "ax[0].set_ylabel('Value (std)')\n",
    "ax[0].set_title(\"Activity type = %s\" % SPORT_CODES[y_train[16]])\n",
    "ax[0].grid()\n",
    "\n",
    "sns.lineplot(x_test_std[7], ax=ax[1])\n",
    "ax[1].set_xlabel('Signal length (s)')\n",
    "ax[1].set_ylabel('Value (std)')\n",
    "ax[1].set_title(\"Activity type = %s\" % SPORT_CODES[y_test[7]])\n",
    "ax[1].grid()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the effect of standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1,figsize=(10,6))\n",
    "sns.lineplot(x_train[16], ax=ax[0])\n",
    "ax[0].set_xlabel('Signal length (s)')\n",
    "ax[0].set_ylabel('Value (std)')\n",
    "ax[0].set_title(\"Activity type = %s\" % SPORT_CODES[y_train[16]])\n",
    "ax[0].grid()\n",
    "\n",
    "sns.lineplot(x_train_std[16], ax=ax[1])\n",
    "ax[1].set_xlabel('Signal length (s)')\n",
    "ax[1].set_ylabel('Value (std)')\n",
    "ax[1].set_title(\"Activity type = %s\" % SPORT_CODES[y_train[16]])\n",
    "ax[1].grid()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = x_train_std[np.where(y_train==0)]\n",
    "label2 = x_train_std[np.where(y_train==1)]\n",
    "label3 = x_train_std[np.where(y_train==2)]\n",
    "\n",
    "print(len(label1), len(label2), len(label3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or without indexes\n",
    "pd.DataFrame(y_train.astype(int)).value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random activities (for each category)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title { run: \"auto\" }\n",
    "rand_index = 32 #@param {type:\"slider\", min:0, max:42, step:1}\n",
    "\n",
    "fig, ax = plt.subplots(3,1, figsize=(10,8), sharey=True)\n",
    "fig.suptitle('Distinct plots for each category')\n",
    "ax[0].plot(label1[rand_index], label='Biking')\n",
    "ax[0].legend(loc='upper left', bbox_to_anchor=(0, 1))\n",
    "ax[0].grid()\n",
    "ax[1].plot(label2[rand_index], label='Running')\n",
    "ax[1].legend(loc='upper left', bbox_to_anchor=(0, 1))\n",
    "ax[1].grid()\n",
    "ax[2].plot(label3[rand_index], label='Other')\n",
    "ax[2].legend(loc='upper left', bbox_to_anchor=(0, 1))\n",
    "ax[2].grid()\n",
    "# Set common labels\n",
    "plt.setp(ax, ylabel='Standard value')\n",
    "plt.setp(ax, xlabel='Signal length (s)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(12,3))\n",
    "fig.suptitle('Combined plot', y=1.1)\n",
    "ax.plot(label1[rand_index], label='Biking')\n",
    "ax.plot(label2[rand_index], label='Running', c='grey', alpha=0.5)\n",
    "ax.plot(label3[rand_index], label='Other', c='navy', alpha=0.5)\n",
    "ax.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left',\n",
    "                      ncol=3, mode=\"expand\", borderaxespad=0.)\n",
    "plt.xlabel('Signal length (s)')\n",
    "plt.ylabel('Value (std)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random activities (for same category)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title { run: \"auto\" }\n",
    "rand_index1 = 10 #@param {type:\"slider\", min:0, max:42, step:1}\n",
    "rand_index2 = 13 #@param {type:\"slider\", min:0, max:42, step:1}\n",
    "rand_index3 = 15 #@param {type:\"slider\", min:0, max:42, step:1}\n",
    "label = label2 #@param [\"label1\", \"label2\", \"label3\"] {type: \"raw\"}\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.suptitle(\"Random sequences of the same category: Running\", y=1.1)\n",
    "plt.plot(label[rand_index1], lw=1, label='Index ' + str(rand_index1))\n",
    "plt.plot(label[rand_index2], lw=1, label='Index ' + str(rand_index2), c='grey', alpha=0.5)\n",
    "plt.plot(label[rand_index3], lw=1, label='Index ' + str(rand_index3), c='navy', alpha=0.5)\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc='lower left',\n",
    "                      ncol=3, mode=\"expand\", borderaxespad=0.)\n",
    "plt.xlabel('Signal length (s)')\n",
    "plt.ylabel('Value (std)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "## [▲](#0) 3 - Univariate Time Series Classification (UTSC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKTIME\n",
    "- [X] Time Series Forest Classifier\n",
    "- [X] Supervised Time Series Forest\n",
    "- [X] Random Interval Spectral Ensemble (RISE)\n",
    "- [X] Random Interval Classifier\n",
    "- [X] Shapelet Transform Classifier\n",
    "- [X] KNeighbors Time Series Classifier\n",
    "- [X] Composable Time Series Forest Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"31\"></a> <br>\n",
    "### [▲](#3) 3A - Libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sktime univariate classifiers\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.classification.interval_based import SupervisedTimeSeriesForest\n",
    "from sktime.classification.interval_based import RandomIntervalSpectralEnsemble # RISE\n",
    "from sktime.classification.feature_based import RandomIntervalClassifier        # Rotation Forest\n",
    "from sktime.classification.compose import ComposableTimeSeriesForestClassifier\n",
    "from sktime.classification.shapelet_based import ShapeletTransformClassifier\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.classification.hybrid import HIVECOTEV1\n",
    "from sktime.classification.dictionary_based import WEASEL\n",
    "\n",
    "# Sktime - Multivariate\n",
    "from sktime.classification.dictionary_based import MUSE\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, mean_squared_error\n",
    "\n",
    "# Time and Progress bar solution (tqdm)\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Extra tools\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper functions and variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confmatrix(ax, yval, ypred):\n",
    "    cm = pd.DataFrame(confusion_matrix(yval, ypred))\n",
    "    cm_norm = cm.apply(lambda x: x/x.sum(), axis = 1)\n",
    "    sns.set(font_scale=1.1) # for label size\n",
    "    sns.heatmap(cm_norm, annot=True, xticklabels=('Biking', 'Running','Other'), \n",
    "                                     yticklabels=('Biking', 'Running','Other'),\n",
    "                                     fmt='.1%',\n",
    "                                     cmap='Blues',\n",
    "                                     ax=ax,\n",
    "                                     annot_kws={\"size\": 16}) # font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report properties for matplotlip.table\n",
    "col_colors = ['lightgray','lightgray','lightgray','skyblue','skyblue','skyblue']\n",
    "row_colors = ['lightgray','lightgray','lightgray','lightgray']\n",
    "cell_colors = [['white','white','white','lightgray','white','white'],\n",
    "               ['white','white','white','lightgray','white','white'],\n",
    "               ['white','white','white','lightgray','white','white'],\n",
    "               ['white','white','white','lightgray','white','white']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creates list of column names according to the parameters\n",
    "- @general: Start of the column name\n",
    "- @num: Identification number for column\n",
    "Output for function call create_col_names(general='Score', num=3) \n",
    "=> ['Score 1','Score 2', 'Score 3']\n",
    "'''\n",
    "def create_col_names(general, num, info=False):\n",
    "    col_names = []\n",
    "    for i in range(1,num+1):\n",
    "        col_names.append(general + str(i))\n",
    "    \n",
    "    if info: print(\"Columns created: \", col_names)\n",
    "    \n",
    "    return col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Saves data to the latest file in a given directory. \n",
    "Inserts a row to a classification result table or a column to a prediction result table.\n",
    "Return the saved data back (data parameter passed in function call).\n",
    "\n",
    "Expected parameter values:\n",
    "- type = ['results','predictions'] - this will define to which actual file (path and filename) data will be inserted\n",
    "- classifier = The name (appreviation) of the classifier as it appears in the column name of the data given as parameter\n",
    "- data = pandas dataframe object. For type='results' assumed to be one row, and for type='predictions' one column.\n",
    "\n",
    "NOTE: Function uses global file paths defined in *1B - Data download* -section\n",
    "'''\n",
    "def save_to_file(type:str, classifier:str, data:pd.DataFrame):\n",
    "    \n",
    "    if type == 'results':\n",
    "        results_csv_filename = os.listdir(results_filepath)[-1]\n",
    "        results_temp = pd.read_csv(results_filepath + results_csv_filename)\n",
    "        results_temp = pd.concat((results_temp, data), axis=0, ignore_index=True)\n",
    "        results_temp.to_csv(results_filepath + results_csv_filename, index=False)\n",
    "        print('Results saved into file: ' + results_csv_filename)\n",
    "        \n",
    "    elif type == 'predictions':\n",
    "        preds_csv_filename = os.listdir(preds_filepath)[-1]\n",
    "        preds_temp = pd.read_csv(preds_filepath + preds_csv_filename)\n",
    "        preds_temp[classifier] = data[classifier]\n",
    "        preds_temp.to_csv(preds_filepath + preds_csv_filename, index=False)\n",
    "        print('Predictions saved into file: ' + preds_csv_filename)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This classification funtion takes models and data as a function parameters ans prints out the results.\n",
    "Notice, that results are only printed immediately when classification is completed, but nothing is stored. \n",
    "Therefore, when execution fails all the data will be lost. Be careful!\n",
    "'''\n",
    "def classify_report(models, x_train, y_train, x_test, y_test):\n",
    "    for name, sktime_clf in models.items():\n",
    "        # Classify\n",
    "        clf = sktime_clf \n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "        print(name, accuracy_score(y_test, y_pred))\n",
    "        # Create figure and grid for different subplots\n",
    "        fig = plt.figure(figsize=(18,3))\n",
    "        spec = gridspec.GridSpec(ncols=2, nrows=1, width_ratios=[1, 2], wspace=0.3)\n",
    "        # Plot confusion matrix\n",
    "        ax1 = fig.add_subplot(spec[0])\n",
    "        plot_confmatrix(ax1, y_test, y_pred)\n",
    "        ax1.set_xlabel('Predicted')\n",
    "        ax1.set_ylabel('Actual')\n",
    "        # Plot classification report\n",
    "        report = pd.DataFrame(classification_report(y_test, y_pred, digits=3, output_dict=True))\n",
    "        ax2 = fig.add_subplot(spec[1])\n",
    "        font_size=16\n",
    "        bbox=[0, 0, 1, 1]\n",
    "        ax2.axis('off')\n",
    "        mpl_table = ax2.table(cellText=np.round(report.values,4), \n",
    "                            rowLabels=report.index, bbox=bbox, \n",
    "                            colLabels=report.columns,\n",
    "                            colColours=col_colors,\n",
    "                            rowColours=row_colors,\n",
    "                            cellColours=cell_colors,\n",
    "                            edges='closed')\n",
    "        mpl_table.auto_set_font_size(False)\n",
    "        mpl_table.set_fontsize(font_size)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Classification function which creates result tables. However, it does not create or print out any kind of analysis, \n",
    "such as correlation matrixes etc.\n",
    "Data given as parameters have to be according to the classifier's requirements. \n",
    "Usability for different type of classifiers is quite flexible. \n",
    "Remember to use correct classifier type name from the list\n",
    "clf_type = sktime | sklearn | sklearn-tree\n",
    "'''\n",
    "def classify(classifiers, clf_type, X_train, X_test, y_train, y_test, results, preds, iters):\n",
    "    # Pandas dataframe for results\n",
    "    if results is None:\n",
    "        results = pd.DataFrame(columns=['Classifier','Type','Train(t)','Test(t)'])\n",
    "        preds = pd.DataFrame()\n",
    "    \n",
    "    # Create column names for scores according to the number of iterations\n",
    "    score_col_names = create_col_names('Score_', iters)\n",
    "    \n",
    "    # Create progress bar with non-default styles\n",
    "    progress_bar = tqdm(classifiers.items(), ncols=100, colour='#87ceeb', file=sys.stdout)\n",
    "    \n",
    "    for name, clf in progress_bar:\n",
    "        progress_bar.set_description(\"Processing \\033[1m ➥%s \\033[0m\" % str(clf)) # Includes bold text printing\n",
    "        score_row = pd.DataFrame(data={'Classifier': name,'Type': clf_type,}, index=[0])\n",
    "        \n",
    "        # Insert score colums for each iterations\n",
    "        for i in range(1,iters+1):\n",
    "            score_row[score_col_names] = 0\n",
    "        \n",
    "        best_score = 0\n",
    "\n",
    "        for iter in range(1,iters+1):\n",
    "            start = time() # Start timing the model\n",
    "            clf.fit(X_train, y_train)\n",
    "            train_time = time() - start # Stop train timer\n",
    "            start = time()              # Start test timer\n",
    "            # Predictions\n",
    "            y_pred = clf.predict(X_test)\n",
    "            # Model scores\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "            score_time = time()-start\n",
    "            # Set values (note: time data will be overwritten in each iteration)\n",
    "            score_row['Train(t)'] = train_time\n",
    "            score_row['Test(t)'] = score_time\n",
    "            score_row[score_col_names[iter-1]] = score\n",
    "            # Among iterations, we could take only one mse, f1 and roc. We store them for the best accuracy.\n",
    "            if score > best_score:\n",
    "                # STORE PREDICTIONS to a data frame\n",
    "                preds[name] = y_pred\n",
    "                # More metrics: MSE, F1 and ROC-AUC scores\n",
    "                score_row['mse'] = mean_squared_error(y_test, y_pred)\n",
    "                score_row['f1'] = f1_score(y_test, y_pred, average='micro')\n",
    "                if clf_type not in ['sklearn']:\n",
    "                    y_pred_proba = clf.predict_proba(X_test)\n",
    "                    score_row['roc-auc'] = roc_auc_score(y_test, y_pred_proba, average=\"weighted\", multi_class=\"ovr\")\n",
    "                else:\n",
    "                    score_row['roc-auc'] = np.nan\n",
    "                best_score = score\n",
    "            \n",
    "        results = pd.concat((results, score_row), axis=0, ignore_index=True)\n",
    "        \n",
    "    print('Classification done for ' + clf_type + '\\n')\n",
    "    \n",
    "    return results, preds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"32\"></a> <br>\n",
    "### [▲](#3) 3B - Data setup\n",
    "\n",
    "Here we initialize global variables \n",
    "`x_data_std, y_data, x_train_std, x_test_std, y_train, y_test` using function `init_data(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_data(SEQ_START, SEQ_END, nest=True, tab=True, std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data to count category distribution in train and test data\n",
    "y_train_labels = pd.DataFrame(y_train.astype(int), columns=['cat'])\n",
    "y_train_labels.cat.replace(SPORT_CODES.keys(), SPORT_CODES.values(), inplace=True)\n",
    "y_train_labels['split'] = 'train'\n",
    "y_test_labels = pd.DataFrame(y_test.astype(int), columns=['cat'])\n",
    "y_test_labels.cat.replace(SPORT_CODES.keys(), SPORT_CODES.values(), inplace=True)\n",
    "y_test_labels['split'] = 'test'\n",
    "cat_distribut_tbl = pd.concat([y_train_labels, y_test_labels])\n",
    "#cat_distribut_tbl = cat_distribut_tbl.groupby(['cat', 'split'])['cat'].count().unstack('split')\n",
    "\n",
    "# Plot dataframe\n",
    "fig, ax = plt.subplots(1,1,figsize=(6,2.5))\n",
    "cat_distribut_tbl.plot(kind='barh',\n",
    "                       stacked=True,\n",
    "                       width=0.5,\n",
    "                       title='Category distribution',\n",
    "                       #color=[THEMA_COLOR, 'skyblue'],\n",
    "                       grid=True,\n",
    "                       ax=ax).legend(loc='lower right')\n",
    "plt.xlabel('Number of instances')\n",
    "plt.ylabel('Category')\n",
    "plt.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_distribut_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "databar = pd.DataFrame(data=cat_distribut_tbl['cat'].value_counts())\n",
    "databar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(8,3))\n",
    "databar.plot(kind='barh', color=THEMA_COLOR, zorder=3,\n",
    "                  width=0.5,\n",
    "                  title='Category distribution',\n",
    "                  grid=True, legend=False, ax=ax)\n",
    "ax.set_xlabel('Number of instances')\n",
    "ax.set_ylabel('Category')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal visualization in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, counts = np.unique(y_test, return_counts=True)\n",
    "print(labels, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_nest_std.rename(columns={0:'dim_0'}).head() # For report we change the column name temporarily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    fig, ax = plt.subplots(1, figsize=plt.figaspect(0.25))\n",
    "    for instance in X_test_nest_std.loc[y_test==label, 0]:\n",
    "        ax.plot(instance, label='label')\n",
    "    ax.set(title=f\"Instances of {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=plt.figaspect(0.25))\n",
    "for label in labels:\n",
    "    X_test_nest_std.loc[y_test==label, 0].iloc[0].plot(ax=ax, label=f\"class {label}\")\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "ax.set(title=\"Example time series\", xlabel=\"Time\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"33\"></a> <br>\n",
    "### [▲](#3) 3C - Univariate TSC model classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sktime models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sktime_clfs = {\n",
    "    'TSF': TimeSeriesForestClassifier(),\n",
    "    'STSF': SupervisedTimeSeriesForest(),\n",
    "    'RISE': RandomIntervalSpectralEnsemble(),\n",
    "    'RIC': RandomIntervalClassifier(),\n",
    "    'STC': ShapeletTransformClassifier(),\n",
    "    'kNN-TS': KNeighborsTimeSeriesClassifier(),\n",
    "    'CTSF': ComposableTimeSeriesForestClassifier(), # Time consuming (~30-40min)\n",
    "    'WEASEL': WEASEL(),\n",
    "    #'HIVE-COTEv1.0': HIVECOTEV1(),                                                 # Extreme time consuming (one succesful run in 900min=15h)\n",
    "    #'CanonicalIntervalForest': CanonicalIntervalForest(),                          # Extreme time consuming\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification with modelwise reports (Disabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify_report(sktime_clfs, X_train_nest_std, y_train, X_test_nest_std, y_test)\n",
    "# This is HIVE-COTE result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single models test (Disabled)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST** TSF EXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_tsf = TimeSeriesForestClassifier()\n",
    "#classify_report({'TSF':clf_tsf}, X_train_nest_std, y_train, X_test_nest_std, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST** HIVECOTE EXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This took time 900 min\n",
    "#sktime_clfs_e1 = {'HIVE-COTE': HIVECOTEV1()}\n",
    "#classify_report(sktime_clfs_e1, X_train_nest_std, y_train, X_test_nest_std, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hive_cote_report](./img/classification_report_hivecote1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST** WEASEL EXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sktime_clfs_e2 = {'WEASEL': WEASEL()}\n",
    "#classify_report(sktime_clfs_e2, X_train_nest_std, y_train, X_test_nest_std, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_data(SEQ_START, SEQ_END, nest=True, tab=True, std=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; padding: 15px; background-color: skyblue; height: 60px; border-radius: 5px; width: 95vw;\">\n",
    "    <h3 style=\"font-size: 20px;\"><b>Classify</b> - Data setup B</h3><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERS = 3\n",
    "#Please Note, this may take time about ~20 min per iteration with ~500 features\n",
    "results, preds = classify(sktime_clfs, 'sktime', X_train_nest_std, X_test_nest_std, y_train, y_test, results=None, preds=None, iters=ITERS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the data before saving**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values('Score_1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save results, scores and predictions to the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp = datetime.datetime.now().strftime(\"D%Y%m%d_T%H%M\")\n",
    "results_csv_filename = 'results_datasetup_b_' + time_stamp + '.csv'\n",
    "preds_csv_filename = 'preds_datasetup_b_' + time_stamp + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(results_filepath + results_csv_filename, index=False)\n",
    "preds.to_csv(preds_filepath + preds_csv_filename, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the case data** \n",
    "\n",
    "* This is for later analysis (every time different test data)\n",
    "* This must be done before `init_data()`function call in order to maintain the same CASE-data which was used in the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_data_train = pd.DataFrame(np.column_stack((x_train_std, y_train)))\n",
    "case_data_train.to_csv('DATA/case_data/TRAIN-DATA_CASE-' + time_stamp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_data_test = pd.DataFrame(np.column_stack((x_test_std, y_test)))\n",
    "case_data_test.to_csv('DATA/case_data/TEST-DATA_CASE-' + time_stamp, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual TSC classification (Disabled)\n",
    "\n",
    "* Here you can try classification with a single model (or smaller subset of classifiers) using the same functions\n",
    "* You can insert results to existing saved tables using *read-modify-save* method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_data(SEQ_START, SEQ_END, nest=True, tab=True, std=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current model: cBOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sktime.classification.dictionary_based import ContractableBOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ITERS = 1\n",
    "sktime_clfs_e2 = {'cBOSS': ContractableBOSS()}\n",
    "results_cboss, preds_cboss = classify(sktime_clfs_e2, 'sktime', X_train_nest_std, X_test_nest_std, y_train, y_test, results=None, preds=None, iters=ITERS)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_cboss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads latest predictions from the existing file and inserts a new prediction column to the table. Then file will be saved again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "preds_csv_filename = os.listdir(preds_filepath)[-1]\n",
    "preds_csv_filename\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "preds_temp = pd.read_csv(preds_filepath + preds_csv_filename)\n",
    "preds_temp['cBOSS'] = preds.cBOSS\n",
    "preds_temp['Correct'] = y_test\n",
    "preds_temp.to_csv(preds_filepath + preds_csv_filename, index=False)\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC-AUC -curve analysis\n",
    "\n",
    "For practical reason we do this here for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import RocCurveDisplay, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('DATA/case_data/TRAIN-DATA_CASE-D20230424_T1718')\n",
    "test_data = pd.read_csv('DATA/case_data/TEST-DATA_CASE-D20230424_T1718')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.iloc[:,:-1].values\n",
    "y_train = train_data['207']\n",
    "x_test = test_data.iloc[:,:-1].values\n",
    "y_test = test_data['207']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sktime_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sktime_clfs.get('TSF').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sktime_clfs.get('TSF').predict(x_test)\n",
    "y_score = sktime_clfs.get('TSF').predict_proba(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we use a LabelBinarizer to binarize the target by one-hot-encoding in a OvR fashion. This means that the target of shape (n_samples,) is mapped to a target of shape (n_samples, n_classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer().fit(y_train)\n",
    "y_onehot_test = label_binarizer.transform(y_test)\n",
    "y_onehot_test.shape  # (n_samples, n_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can as well easily check the encoding of a specific class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer.transform([1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curve showing a specific class\n",
    "\n",
    "- In the following plot we show the resulting ROC curve when regarding the sports as either “biking” (class_id=0) or “non-biking” (the rest 1 or 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_of_interest = 0\n",
    "class_id = np.flatnonzero(label_binarizer.classes_ == class_of_interest)[0]\n",
    "class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print roc-auc using sklearn function\n",
    "print(roc_auc_score(y_test, y_score, average=\"weighted\", multi_class=\"ovr\"))\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(20,8))\n",
    "\n",
    "for f in [0,1,2]:\n",
    "\n",
    "    class_of_interest = f\n",
    "    class_id = np.flatnonzero(label_binarizer.classes_ == class_of_interest)[0]\n",
    "\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_onehot_test[:, class_id],\n",
    "        y_score[:, class_id],\n",
    "        name=f\"{class_of_interest} vs the rest\",\n",
    "        color=\"darkorange\",\n",
    "        ax=ax[f]\n",
    "    )\n",
    "    ax[f].plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "    ax[f].axis(\"square\")\n",
    "    ax[f].set_xlabel(\"False Positive Rate\")\n",
    "    ax[f].set_ylabel(\"True Positive Rate\")\n",
    "    ax[f].set_title(\"One-vs-Rest ROC curves:\\nBiking vs (Running & Other)\")\n",
    "    ax[f].legend()\n",
    "\n",
    "fig.suptitle('Time Series Forest (TSF) ROC_AUC curves', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "## [▲](#0) 4 - Multivariate TSC (MTSC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"41\"></a> <br>\n",
    "### [▲](#4) 4A - Libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.dictionary_based import MUSE # WEASEL+MUSE (multivariate version of WEASEL)\n",
    "from sktime.classification.compose import ColumnEnsembleClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sktime.datatypes._panel._convert import from_2d_array_to_nested"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"42\"></a> <br>\n",
    "### [▲](#4) 4B - Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_list = np.array([seq.T[0] for seq in SEQ_SEGMENTED])\n",
    "spd_list = np.array([seq.T[1] for seq in SEQ_SEGMENTED])\n",
    "alt_list = np.array([seq.T[2] for seq in SEQ_SEGMENTED])\n",
    "\n",
    "hr_std = (hr_list - hr_list.mean())/(hr_list.std())\n",
    "spd_std = (spd_list - spd_list.mean())/(spd_list.std())\n",
    "alt_std = (alt_list - alt_list.mean())/(alt_list.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_std.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save data to file in order to access it later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(hr_std).to_csv('DATA/HR-DATA_std_1160x69', index=False)\n",
    "pd.DataFrame(spd_std).to_csv('DATA/SPD-DATA_std_1160x69', index=False)\n",
    "pd.DataFrame(alt_std).to_csv('DATA/ALT-DATA_std_1160x69', index=False)\n",
    "pd.DataFrame(SEQ_SEGMENTED_LABELS.label).to_csv('DATA/TARGET-DATA_1160x69', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Segment visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4,2,figsize=(20,12))\n",
    "\n",
    "def plot_sample(ax, data, title, legend=['1','2','3','4','5'], loc='upper right', color=None):\n",
    "    ax.set_title(title)\n",
    "    ax.plot(data, color=color)\n",
    "    ax.legend(legend, loc=loc)\n",
    "\n",
    "# Original data plots\n",
    "plot_sample(ax[0,0], hr_list[0:5].T, 'Heart Rate')\n",
    "plot_sample(ax[1,0], spd_list[0:5].T, 'Speed')\n",
    "plot_sample(ax[2,0], alt_list[0:5].T, 'Altitude')\n",
    "\n",
    "# Scaled data plots\n",
    "plot_sample(ax[0,1], hr_std[0:5].T, 'Heart Rate')\n",
    "plot_sample(ax[1,1], spd_std[0:5].T, 'Speed')\n",
    "plot_sample(ax[2,1], alt_std[0:5].T, 'Altitude')\n",
    "\n",
    "# Plot activity features\n",
    "plot_sample(ax[3,0], hr_list[0], title='', color='red')\n",
    "plot_sample(ax[3,0], spd_list[0], title='', color='blue')\n",
    "plot_sample(ax[3,0], alt_list[0], title='Activity 1', legend=['hr','spd','alt'], color='green')\n",
    "\n",
    "plot_sample(ax[3,1], hr_list[3], title='', color='red')\n",
    "plot_sample(ax[3,1], spd_list[3], title='', color='blue')\n",
    "plot_sample(ax[3,1], alt_list[3], title='Activity 4', legend=['hr','spd','alt'], color='green')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2,figsize=(20,6))\n",
    "\n",
    "# Plot activity features\n",
    "ax[0,0].set_title('Activity A')\n",
    "ax[0,0].plot(hr_list[0], color='red')\n",
    "ax[0,0].plot(spd_list[0], color='blue')\n",
    "ax[0,0].plot(alt_list[0], color='green')\n",
    "ax[0,0].legend(['hr','spd','alt'], loc='upper right')\n",
    "\n",
    "ax[0,1].set_title('Activity A (std)')\n",
    "ax[0,1].plot(hr_std[0], color='red')\n",
    "ax[0,1].plot(spd_std[0], color='blue')\n",
    "ax[0,1].plot(alt_std[0], color='green')\n",
    "ax[0,1].legend(['hr','spd','alt'], loc='upper right')\n",
    "\n",
    "ax[1,0].set_title('Activity B')\n",
    "ax[1,0].plot(hr_list[3], color='red')\n",
    "ax[1,0].plot(spd_list[3], color='blue')\n",
    "ax[1,0].plot(alt_list[3], color='green')\n",
    "ax[1,0].legend(['hr','spd','alt'], loc='upper right')\n",
    "\n",
    "ax[1,1].set_title('Activity B (std)')\n",
    "ax[1,1].plot(hr_std[3], color='red')\n",
    "ax[1,1].plot(spd_std[3], color='blue')\n",
    "ax[1,1].plot(alt_std[3], color='green')\n",
    "ax[1,1].legend(['hr','spd','alt'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform features separately to a nested structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nest_hr = from_2d_array_to_nested(np.array(hr_std))\n",
    "df_nest_spd = from_2d_array_to_nested(np.array(spd_std))\n",
    "df_nest_alt = from_2d_array_to_nested(np.array(alt_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nest_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multi = pd.DataFrame()\n",
    "df_multi['hr'] = df_nest_hr\n",
    "df_multi['spd'] = df_nest_spd\n",
    "df_multi['alt'] = df_nest_alt\n",
    "df_multi['target'] = SEQ_SEGMENTED_LABELS.label.astype('category')\n",
    "df_multi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train-test splits for actual classification (we use the same splits for MUSE and ensemble)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"43\"></a> <br>\n",
    "### [▲](#4) 4C - Multivariate TSC model classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Create train/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(df_multi.iloc[:,0:3], \n",
    "                                          df_multi.iloc[:,3].cat.codes, \n",
    "                                          test_size=0.2, \n",
    "                                          random_state=24, \n",
    "                                          stratify=df_multi.iloc[:,3], \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`class MUSE(anova=True, \n",
    "            variance=False, \n",
    "            bigrams=True, \n",
    "            window_inc=2, \n",
    "            alphabet_size=4, \n",
    "            use_first_order_differences=True, \n",
    "            feature_selection='chi2', \n",
    "            p_threshold=0.05, \n",
    "            support_probabilities=False, \n",
    "            n_jobs=1,  \n",
    "            random_state=None)`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sktime_clfs_e3 = {'MUSE': MUSE(window_inc=4)}\n",
    "classify_report(sktime_clfs_e3, x_tr, y_tr, x_te, y_te)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Iterative classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Modify `classify()` function to allow probability calculation also for `sktime-multivariate` and `sktime-ensemble` types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_muse, preds_muse = classify(sktime_clfs_e3, 'sktime-multivar', x_tr, x_te, y_tr, y_te, results=None, preds=None, iters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_muse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_muse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_file('results','MUSE',results_muse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_file('predictions','MUSE',preds_muse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"44\"></a> <br>\n",
    "### [▲](#4) 4D - Column Ensemble classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate separate feature classification\n",
    ">> In order to find best models for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERS = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0 - Heart Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(df_nest_hr, \n",
    "                                          df_multi.target.cat.codes, \n",
    "                                          test_size=0.2, \n",
    "                                          random_state=24, \n",
    "                                          stratify=df_multi.target, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_hr, preds_hr = classify(sktime_clfs, 'sktime', x_tr, x_te, y_tr, y_te, results=None, preds=None, iters=ITERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_hr['Exec_Time(s)'] = results_hr['Train(t)']+results_hr['Test(t)']\n",
    "results_hr['train/test(s)'] = (results_hr['Exec_Time(s)']-results_hr['Exec_Time(s)'].min())/(results_hr['Exec_Time(s)'].max()-results_hr['Exec_Time(s)'].min())\n",
    "results_hr.sort_values('Score_1', ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 - Speed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(df_nest_spd, \n",
    "                                          df_multi.target.cat.codes, \n",
    "                                          test_size=0.2, \n",
    "                                          random_state=24, \n",
    "                                          stratify=df_multi.target, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_spd, preds_spd = classify(sktime_clfs, 'sktime', x_tr, x_te, y_tr, y_te, results=None, preds=None, iters=ITERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_spd['Exec_Time(s)'] = results_spd['Train(t)']+results_spd['Test(t)']\n",
    "results_spd['train/test(s)'] = (results_spd['Exec_Time(s)']-results_spd['Exec_Time(s)'].min())/(results_spd['Exec_Time(s)'].max()-results_spd['Exec_Time(s)'].min())\n",
    "results_spd.sort_values('Score_1', ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 - Altitude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(df_nest_alt, \n",
    "                                          df_multi.target.cat.codes, \n",
    "                                          test_size=0.2, \n",
    "                                          random_state=24, \n",
    "                                          stratify=df_multi.target, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_alt, preds_alt = classify(sktime_clfs, 'sktime', x_tr, x_te, y_tr, y_te, results=None, preds=None, iters=ITERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_alt['Exec_Time(s)'] = results_alt['Train(t)']+results_alt['Test(t)']\n",
    "results_alt['train/test(s)'] = (results_alt['Exec_Time(s)']-results_alt['Exec_Time(s)'].min())/(results_alt['Exec_Time(s)'].max()-results_alt['Exec_Time(s)'].min())\n",
    "results_alt.sort_values('Score_1', ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column Ensemble\n",
    "\n",
    "According to the single feature classification results we select the following models to ensemble\n",
    "\n",
    "| Feature | Classifier | Result |\n",
    "|    -    |     -      |   -    |\n",
    "| HeartRate | Supervised Time Series Forest (STSF) | 0.58 |\n",
    "| Speed| Supervised Time Series Forest (STSF) | 0.92 |\n",
    "| Altitude | Random Interval Classifier (STSF) | 0.79 |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to initialize data variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(df_multi.iloc[:,0:3], \n",
    "                                          df_multi.iloc[:,3].cat.codes, \n",
    "                                          test_size=0.2, \n",
    "                                          random_state=24, \n",
    "                                          stratify=df_multi.iloc[:,3], \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_emb = ColumnEnsembleClassifier( estimators=[\n",
    "                                    (\"STSF1\", SupervisedTimeSeriesForest(), [0]),  # column 1\n",
    "                                    (\"STSF2\", SupervisedTimeSeriesForest(), [1]),  # column 2\n",
    "                                    (\"RIC\", RandomIntervalClassifier(), [2]),      # column 3\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sktime_clfs_e4 = {'ENSEMBLE': clf_emb}\n",
    "classify_report(sktime_clfs_e4, x_tr, y_tr, x_te, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_emb, preds_emb = classify(sktime_clfs_e4, 'sktime-ensemble', x_tr, x_te, y_tr, y_te, results=None, preds=None, iters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_emb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Save results to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_file('results','ENSEMBLE',results_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_file('predictions','ENSEMBLE',preds_emb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: block; padding: 15px; background-color: lightgreen; height: auto; border-radius: 5px; width: 95vw;\">\n",
    "    <h3 style=\"font-size: 26px;\"><b>Execution Information</b></h3>\n",
    "    <p>Works only when the whole file is executed from start to this point</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_end = datetime.datetime.now()\n",
    "run_time = run_end - run_start\n",
    "print('File execution info:')\n",
    "print('Start\\t', run_start)\n",
    "print('End\\t', run_end)\n",
    "print('Runtime\\t', str(run_time))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a> <br>\n",
    "# [▲](#CT) 7 - Test Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Some extra time series classifiers from sktime\n",
    "from sktime.classification.compose import ColumnEnsembleClassifier\n",
    "from sktime.classification.feature_based import SummaryClassifier\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "# Data transformation tools from sktime\n",
    "from sktime.transformations.panel.compose import ColumnConcatenator\n",
    "from sktime.transformations.panel.segment import RandomIntervalSegmenter\n",
    "from sktime.transformations.panel.shapelet_transform import ShapeletTransform\n",
    "# Model tuning tools\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "# Dataset for testing purposes\n",
    "from sktime.datasets import load_basic_motions\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# Metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sktime.datasets import load_unit_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7A - Column Ensemble in \"Basic Motions\" dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix plot function (for 4 class in test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confmatrix_4(ax, yval, ypred):\n",
    "    cm = pd.DataFrame(confusion_matrix(yval, ypred))\n",
    "    cm_norm = cm.apply(lambda x: x/x.sum(), axis = 1)\n",
    "    sns.set(font_scale=1.1) # for label size\n",
    "    sns.heatmap(cm_norm, annot=True, xticklabels=('Pred A1', 'Pred A2','Pred A3','Pred A4'), \n",
    "                                     yticklabels=('Act A1', 'Act A2','Act A3','Act A4'),\n",
    "                                     fmt='.1%',\n",
    "                                     cmap='Blues',\n",
    "                                     ax=ax,\n",
    "                                     annot_kws={\"size\": 16}) # font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_basic_motions(split=\"train\")\n",
    "X_test, y_test = load_basic_motions(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimators (Models)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(\"STSF\", SupervisedTimeSeriesForest(), [0]), \n",
    "              (\"RISE\", RandomIntervalClassifier(), [1, 2])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensemble**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ens = ColumnEnsembleClassifier(estimators=estimators)\n",
    "col_ens.fit(X_train, y_train)\n",
    "\n",
    "y_pred = col_ens.predict(X_test)\n",
    "print('model', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "spec = gridspec.GridSpec(ncols=1, nrows=1, width_ratios=[1], wspace=0.3)\n",
    "ax = fig.add_subplot(spec[0])\n",
    "plot_confmatrix_4(ax, y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Study case data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ColumnEnsembleClassifier( estimators=[\n",
    "                                    (\"STSF\", SupervisedTimeSeriesForest(), [0]),                     # column 1\n",
    "                                    (\"TSFC\", TimeSeriesForestClassifier(n_estimators=200), [1]),     # column ...\n",
    "                                    (\"RISE\", RandomIntervalSpectralEnsemble(n_estimators=200), [2]), # column n\n",
    "                                ])\n",
    "clf.fit(X_train_nest, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_nest)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "plot_confmatrix(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter list of classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_param_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hp = {}\n",
    "for name, model in sktime_clfs.items():\n",
    "    hyperparams = model.get_params()\n",
    "    model_hp[name] = hyperparams\n",
    "\n",
    "model_hp['MUSE'] = muse.get_params()\n",
    "\n",
    "pd.DataFrame(model_hp).replace(np.nan, '', regex=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CML model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML models\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_clfs = {\n",
    "    'kNN':  KNeighborsClassifier(),\n",
    "    'G-NB': GaussianNB(),\n",
    "    'QDA':  QuadraticDiscriminantAnalysis(),\n",
    "    'LR':   LogisticRegression(),\n",
    "    'SVM':  SVC(),\n",
    "    'MLP':  MLPClassifier(),\n",
    "    'LDA':  LinearDiscriminantAnalysis(),\n",
    "    'GB':   GradientBoostingClassifier()\n",
    "}\n",
    "sklearn_clfs_tree = {\n",
    "    'DT':   DecisionTreeClassifier(),\n",
    "    'RF':   RandomForestClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_data(SEQ_START, SEQ_END, nest=False, tab=True)\n",
    "X_train_tab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tab_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sklearn, preds_sklearn = classify(sklearn_clfs, 'sklearn', X_train_tab_std, X_test_tab_std, y_train, y_test, results=None, preds=None, iters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_report(sklearn_clfs_tree, X_train_tab, y_train, X_test_tab, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_report(sklearn_clfs, X_train_tab_std, y_train, X_test_tab_std, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb439c8d518b06493021d3c06b3df7d205c58a04068c29e4300e6346cb8d5882"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
